{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (25.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: polars in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.25.2)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (3.10.1)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.4.2)\n",
      "Requirement already satisfied: openpyxl in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (3.1.5)\n",
      "Requirement already satisfied: fastexcel in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.13.0)\n",
      "Requirement already satisfied: tensorflow in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.16.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/tomas/Library/Python/3.12/lib/python/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: et-xmlfile in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from fastexcel) (19.0.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (4.25.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (75.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/tomas/Library/Python/3.12/lib/python/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow-macos (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow-macos\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install --upgrade pip\n",
    "%pip install polars numpy scikit-learn matplotlib joblib openpyxl fastexcel tensorflow\n",
    "\n",
    "# For TensorFlow on Mac, you need to install tensorflow-macos\n",
    "%pip install tensorflow-macos tensorflow-metal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importación de las librerías a usar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 21:22:21.925 Python[81840:81126064] ApplePersistenceIgnoreState: Existing state will not be touched. New state will be written to /var/folders/b9/dh9qy_tj6p7g8mrkr5cj9rmc0000gn/T/org.python.python.savedState\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "from datetime import timedelta\n",
    "import openpyxl\n",
    "\n",
    "# Configuración de Matplotlib para evitar errores con Tkinter\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de las rutas y sujetos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sujetos: 54\n"
     ]
    }
   ],
   "source": [
    "# Obtener los archivos de los sujetos\n",
    "# Definición de la ruta del proyecto\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "# Definición de la ruta de los archivos de los sujetos\n",
    "SUBJECTS_RELATIVE_PATH = \"data/Subjects\"\n",
    "SUBJECTS_PATH = os.path.join(PROJECT_ROOT, SUBJECTS_RELATIVE_PATH)\n",
    "\n",
    "# Definición de la ruta de salida de las figuras\n",
    "FIGURES_DIR = os.path.join(PROJECT_ROOT, \"figures\", \"baseline\")\n",
    "os.makedirs(FIGURES_DIR, exist_ok=True)\n",
    "\n",
    "subject_files = [f for f in os.listdir(SUBJECTS_PATH) if f.startswith(\"Subject\") and f.endswith(\".xlsx\")]\n",
    "print(f\"Total sujetos: {len(subject_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 1: Preprocesamiento.\n",
    "\n",
    "Leer los datos de los sujetos y preprocesarlos para el modelo, seleccionando las columnas de interés.\n",
    "\n",
    "### Data Preprocessing Functions\n",
    "\n",
    "Definición de las funciones:\n",
    "\n",
    "- `get_cgm_window`: obtiene la ventana de datos de CGM para un tiempo de bolo específico.\n",
    "- `calculate_iob`: calcula la insulina activa en el cuerpo para un tiempo de bolo específico.\n",
    "- `process_subject`: procesa los datos de un sujeto específico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando Subject21.xlsx (1/54)...\n",
      "Procesando Subject37.xlsx (2/54)...\n",
      "Procesando Subject17.xlsx (3/54)...\n",
      "Procesando Subject40.xlsx (4/54)...\n",
      "Procesando Subject6.xlsx (5/54)...\n",
      "Procesando Subject7.xlsx (6/54)...\n",
      "Procesando Subject41.xlsx (7/54)...\n",
      "Procesando Subject16.xlsx (8/54)...\n",
      "Procesando Subject36.xlsx (9/54)...\n",
      "Procesando Subject20.xlsx (10/54)...\n",
      "Procesando Subject11.xlsx (11/54)...\n",
      "Procesando Subject46.xlsx (12/54)...\n",
      "Procesando Subject50.xlsx (13/54)...\n",
      "Procesando Subject27.xlsx (14/54)...\n",
      "Procesando Subject31.xlsx (15/54)...\n",
      "Procesando Subject30.xlsx (16/54)...\n",
      "Procesando Subject26.xlsx (17/54)...\n",
      "Procesando Subject1.xlsx (18/54)...\n",
      "Procesando Subject51.xlsx (19/54)...\n",
      "Procesando Subject47.xlsx (20/54)...\n",
      "Procesando Subject10.xlsx (21/54)...\n",
      "Procesando Subject29.xlsx (22/54)...\n",
      "Procesando Subject2.xlsx (23/54)...\n",
      "Procesando Subject52.xlsx (24/54)...\n",
      "Procesando Subject44.xlsx (25/54)...\n",
      "Procesando Subject13.xlsx (26/54)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not determine dtype for column 5, falling back to string\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando Subject33.xlsx (27/54)...\n",
      "Procesando Subject25.xlsx (28/54)...\n",
      "Procesando Subject48.xlsx (29/54)...\n",
      "Procesando Subject49.xlsx (30/54)...\n",
      "Procesando Subject24.xlsx (31/54)...\n",
      "Procesando Subject32.xlsx (32/54)...\n",
      "Procesando Subject12.xlsx (33/54)...\n",
      "Procesando Subject45.xlsx (34/54)...\n",
      "Procesando Subject53.xlsx (35/54)...\n",
      "Procesando Subject3.xlsx (36/54)...\n",
      "Procesando Subject28.xlsx (37/54)...\n",
      "Procesando Subject35.xlsx (38/54)...\n",
      "Procesando Subject23.xlsx (39/54)...\n",
      "Procesando Subject8.xlsx (40/54)...\n",
      "Procesando Subject19.xlsx (41/54)...\n",
      "Procesando Subject39.xlsx (42/54)...\n",
      "Procesando Subject4.xlsx (43/54)...\n",
      "Procesando Subject54.xlsx (44/54)...\n",
      "Procesando Subject42.xlsx (45/54)...\n",
      "Procesando Subject15.xlsx (46/54)...\n",
      "Procesando Subject14.xlsx (47/54)...\n",
      "Procesando Subject43.xlsx (48/54)...\n",
      "Procesando Subject5.xlsx (49/54)...\n",
      "Procesando Subject38.xlsx (50/54)...\n",
      "Procesando Subject18.xlsx (51/54)...\n",
      "Procesando Subject9.xlsx (52/54)...\n",
      "Procesando Subject22.xlsx (53/54)...\n",
      "Procesando Subject34.xlsx (54/54)...\n",
      "Muestra de datos procesados combinados:\n",
      "shape: (5, 8)\n",
      "┌────────────┬─────────────┬───────────┬─────────┬─────────────┬─────────────┬────────────┬────────┐\n",
      "│ subject_id ┆ cgm_window  ┆ carbInput ┆ bgInput ┆ insulinCarb ┆ insulinSens ┆ insulinOnB ┆ normal │\n",
      "│ ---        ┆ ---         ┆ ---       ┆ ---     ┆ Ratio       ┆ itivityFact ┆ oard       ┆ ---    │\n",
      "│ i64        ┆ object      ┆ i64       ┆ i64     ┆ ---         ┆ or          ┆ ---        ┆ f64    │\n",
      "│            ┆             ┆           ┆         ┆ f64         ┆ ---         ┆ f64        ┆        │\n",
      "│            ┆             ┆           ┆         ┆             ┆ f64         ┆            ┆        │\n",
      "╞════════════╪═════════════╪═══════════╪═════════╪═════════════╪═════════════╪════════════╪════════╡\n",
      "│ 0          ┆ [112 111    ┆ 0         ┆ 167     ┆ 10.0        ┆ 50.0        ┆ 0.0        ┆ 1.238  │\n",
      "│            ┆ 110 112 106 ┆           ┆         ┆             ┆             ┆            ┆        │\n",
      "│            ┆ 104 109 1…  ┆           ┆         ┆             ┆             ┆            ┆        │\n",
      "│ 0          ┆ [106 114    ┆ 0         ┆ 303     ┆ 10.0        ┆ 50.0        ┆ 0.0        ┆ 2.015  │\n",
      "│            ┆ 128 124 118 ┆           ┆         ┆             ┆             ┆            ┆        │\n",
      "│            ┆ 110 112 1…  ┆           ┆         ┆             ┆             ┆            ┆        │\n",
      "│ 0          ┆ [281 300    ┆ 0         ┆ 320     ┆ 10.0        ┆ 50.0        ┆ 0.0        ┆ 1.625  │\n",
      "│            ┆ 234 237 256 ┆           ┆         ┆             ┆             ┆            ┆        │\n",
      "│            ┆ 264 272 2…  ┆           ┆         ┆             ┆             ┆            ┆        │\n",
      "│ 0          ┆ [312 329    ┆ 0         ┆ 217     ┆ 10.0        ┆ 50.0        ┆ 0.0        ┆ 0.536  │\n",
      "│            ┆ 336 343 342 ┆           ┆         ┆             ┆             ┆            ┆        │\n",
      "│            ┆ 326 320 3…  ┆           ┆         ┆             ┆             ┆            ┆        │\n",
      "│ 0          ┆ [118 115    ┆ 0         ┆ 161     ┆ 10.0        ┆ 50.0        ┆ 0.0        ┆ 1.19   │\n",
      "│            ┆ 113 114 114 ┆           ┆         ┆             ┆             ┆            ┆        │\n",
      "│            ┆ 114 120 1…  ┆           ┆         ┆             ┆             ┆            ┆        │\n",
      "└────────────┴─────────────┴───────────┴─────────┴─────────────┴─────────────┴────────────┴────────┘\n",
      "Total muestras: 44651\n"
     ]
    }
   ],
   "source": [
    "def get_cgm_window(bolus_time, cgm_df, window_hours=2) -> np.ndarray:\n",
    "    '''\n",
    "    Obtiene la ventana de datos de CGM para un tiempo de bolo específico.\n",
    "\n",
    "    Parámetros:\n",
    "    - bolus_time: datetime\n",
    "        Tiempo del bolo de insulina.\n",
    "    - cgm_df: pl.DataFrame\n",
    "        Datos de CGM.\n",
    "    - window_hours: int\n",
    "        Número de horas de la ventana de datos.\n",
    "    \n",
    "    Retorna:\n",
    "    - np.ndarray\n",
    "        Ventana de datos\n",
    "    '''\n",
    "    window_start = bolus_time - timedelta(hours=window_hours)\n",
    "    # Filtro y ordenamiento de los datos de CGM\n",
    "    window = cgm_df.filter(\n",
    "        (pl.col(\"date\") >= window_start) & (pl.col(\"date\") <= bolus_time)\n",
    "    ).sort(\"date\").tail(24)\n",
    "    \n",
    "    if window.height < 24:\n",
    "        return None\n",
    "    return window.get_column(\"mg/dl\").to_numpy()\n",
    "\n",
    "def calculate_iob(bolus_time, basal_df, half_life_hours=4) -> float:\n",
    "    '''\n",
    "    Calcula la insulina activa en el cuerpo (IOB) para un tiempo de bolo específico.\n",
    "\n",
    "    Parámetros:\n",
    "    - bolus_time: datetime\n",
    "        Tiempo del bolo de insulina.\n",
    "    - basal_df: pl.DataFrame\n",
    "        Datos de insulina basal.\n",
    "    - half_life_hours: float\n",
    "        Vida media de la insulina en horas.\n",
    "    \n",
    "    Retorna:\n",
    "    - float\n",
    "        Insulina activa en el cuerpo.\n",
    "    '''\n",
    "    if basal_df is None or basal_df.is_empty():\n",
    "        return 0.0\n",
    "    \n",
    "    iob = 0\n",
    "    for row in basal_df.iter_rows(named=True):\n",
    "        start_time = row[\"date\"]\n",
    "        duration_hours = row[\"duration\"] / (1000 * 3600)\n",
    "        end_time = start_time + timedelta(hours=duration_hours)\n",
    "        rate = row[\"rate\"] if row[\"rate\"] is not None else 0.9\n",
    "        \n",
    "        if start_time <= bolus_time <= end_time:\n",
    "            time_since_start = (bolus_time - start_time).total_seconds() / 3600\n",
    "            remaining = rate * (1 - (time_since_start / half_life_hours))\n",
    "            iob += max(0, remaining)\n",
    "    return iob\n",
    "\n",
    "def process_subject(subject_path, idx) -> list:\n",
    "    '''\n",
    "    Procesa los datos de un sujeto específico.\n",
    "\n",
    "    Parámetros:\n",
    "    - subject_path: str\n",
    "        Ruta del archivo de datos del sujeto.\n",
    "    - idx: int\n",
    "        Índice del sujeto.\n",
    "    \n",
    "    Retorna:\n",
    "    - list\n",
    "        Datos procesados del sujeto.\n",
    "    '''\n",
    "    print(f\"Procesando {os.path.basename(subject_path)} ({idx+1}/{len(subject_files)})...\")\n",
    "    \n",
    "    try:\n",
    "        # Carga de los datos del sujeto\n",
    "        cgm_df = pl.read_excel(subject_path, sheet_name=\"CGM\")\n",
    "        bolus_df = pl.read_excel(subject_path, sheet_name=\"Bolus\")\n",
    "        try:\n",
    "            basal_df = pl.read_excel(subject_path, sheet_name=\"Basal\")\n",
    "        except Exception:\n",
    "            basal_df = None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {os.path.basename(subject_path)}: {e}\")\n",
    "        return []\n",
    "\n",
    "    # Conversión de fechas y preordenamiento CGM para cada sujeto\n",
    "    cgm_df = cgm_df.with_columns(pl.col(\"date\").cast(pl.Datetime))\n",
    "    bolus_df = bolus_df.with_columns(pl.col(\"date\").cast(pl.Datetime))\n",
    "    if basal_df is not None:\n",
    "        basal_df = basal_df.with_columns(pl.col(\"date\").cast(pl.Datetime))\n",
    "    \n",
    "    # Preordenamiento para eficiencia\n",
    "    cgm_df = cgm_df.sort(\"date\")\n",
    "\n",
    "    processed_data = []\n",
    "    for row in bolus_df.iter_rows(named=True):\n",
    "        bolus_time = row[\"date\"]\n",
    "        cgm_window = get_cgm_window(bolus_time, cgm_df)\n",
    "        \n",
    "        if cgm_window is not None:\n",
    "            iob = calculate_iob(bolus_time, basal_df)\n",
    "            features = {\n",
    "                'subject_id': idx,\n",
    "                'cgm_window': cgm_window,\n",
    "                'carbInput': row[\"carbInput\"] if row[\"carbInput\"] is not None else 0.0,\n",
    "                'bgInput': row[\"bgInput\"] if row[\"bgInput\"] is not None else cgm_window[-1],\n",
    "                'insulinCarbRatio': row[\"insulinCarbRatio\"] if row[\"insulinCarbRatio\"] is not None else 10.0,\n",
    "                'insulinSensitivityFactor': 50.0,\n",
    "                'insulinOnBoard': iob,\n",
    "                'normal': row[\"normal\"]\n",
    "            }\n",
    "            processed_data.append(features)\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "# Ejecución en paralelo\n",
    "all_processed_data = Parallel(n_jobs=-1)(\n",
    "    delayed(process_subject)(\n",
    "        os.path.join(SUBJECTS_PATH, f), \n",
    "        idx\n",
    "    ) for idx, f in enumerate(subject_files)\n",
    ")\n",
    "\n",
    "all_processed_data = [item for sublist in all_processed_data for item in sublist]\n",
    "\n",
    "# Conversión a DataFrame\n",
    "df_processed = pl.DataFrame(all_processed_data)\n",
    "print(\"Muestra de datos procesados combinados:\")\n",
    "print(df_processed.head())\n",
    "print(f\"Total muestras: {len(df_processed)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División y Combinación de Datos Procesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División de la ventana CGM en columnas\n",
    "cgm_columns = [f'cgm_{i}' for i in range(24)]\n",
    "df_cgm = pl.DataFrame({\n",
    "    col: [row['cgm_window'][i] for row in all_processed_data]\n",
    "    for i, col in enumerate(cgm_columns)\n",
    "},\n",
    "schema={col: pl.Float64 for col in cgm_columns})\n",
    "\n",
    "# Combinación con los datos procesados\n",
    "df_final = pl.concat([\n",
    "    df_cgm,\n",
    "    df_processed.drop('cgm_window')\n",
    "], how=\"horizontal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminación de valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check de valores nulos en df_final:\n",
      "shape: (1, 31)\n",
      "┌───────┬───────┬───────┬───────┬───┬──────────────────┬─────────────────┬────────────────┬────────┐\n",
      "│ cgm_0 ┆ cgm_1 ┆ cgm_2 ┆ cgm_3 ┆ … ┆ insulinCarbRatio ┆ insulinSensitiv ┆ insulinOnBoard ┆ normal │\n",
      "│ ---   ┆ ---   ┆ ---   ┆ ---   ┆   ┆ ---              ┆ ityFactor       ┆ ---            ┆ ---    │\n",
      "│ u32   ┆ u32   ┆ u32   ┆ u32   ┆   ┆ u32              ┆ ---             ┆ u32            ┆ u32    │\n",
      "│       ┆       ┆       ┆       ┆   ┆                  ┆ u32             ┆                ┆        │\n",
      "╞═══════╪═══════╪═══════╪═══════╪═══╪══════════════════╪═════════════════╪════════════════╪════════╡\n",
      "│ 0     ┆ 0     ┆ 0     ┆ 0     ┆ … ┆ 0                ┆ 0               ┆ 0              ┆ 0      │\n",
      "└───────┴───────┴───────┴───────┴───┴──────────────────┴─────────────────┴────────────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "# Eliminar valores nulos en df_final.\n",
    "print(\"Check de valores nulos en df_final:\")\n",
    "df_final = df_final.drop_nulls()\n",
    "print(df_final.null_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 2: Entrenamiento del modelo.\n",
    "Normalización de los datos y división en conjuntos de entrenamiento, validación y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_cgm = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_other = StandardScaler()\n",
    "\n",
    "# Normalizar características\n",
    "X_cgm = scaler_cgm.fit_transform(df_final.select(cgm_columns).to_numpy())\n",
    "X_other = scaler_other.fit_transform(\n",
    "    df_final.select(['carbInput', 'bgInput', 'insulinOnBoard']).to_numpy()\n",
    ")\n",
    "\n",
    "# Combinar características\n",
    "X = np.hstack([\n",
    "    X_cgm, \n",
    "    X_other, \n",
    "    df_final.select(['insulinCarbRatio', 'insulinSensitivityFactor', 'subject_id']).to_numpy()\n",
    "])\n",
    "y = df_final.get_column('normal').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X dtype: float64\n",
      "y dtype: float64\n",
      "NaN in X: 0\n",
      "NaN in y: 0\n"
     ]
    }
   ],
   "source": [
    "# Conversión de arrays a NumPy\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "\n",
    "print(\"X dtype:\", X.dtype)\n",
    "print(\"y dtype:\", y.dtype)\n",
    "\n",
    "def check_nan(arr) -> int:\n",
    "    '''\n",
    "    Función para verificar valores NaN en un array NumPy.\n",
    "\n",
    "    Parámetros:\n",
    "    - arr: np.ndarray\n",
    "        Array NumPy a verificar.\n",
    "\n",
    "    Retorna:\n",
    "    - int\n",
    "        Número de valores NaN en el array.\n",
    "    '''\n",
    "    if np.issubdtype(arr.dtype, np.number):\n",
    "        return np.isnan(arr).sum()\n",
    "    else:\n",
    "        return np.sum([x is None for x in arr])\n",
    "\n",
    "print(\"NaN in X:\", check_nan(X))\n",
    "print(\"NaN in y:\", check_nan(y))\n",
    "\n",
    "# Levantar error si hay valores en NaN\n",
    "if check_nan(X) > 0 or check_nan(y) > 0:\n",
    "    raise ValueError(\"Valores NaN detectados en X o y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División de Datos por Sujeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento: (33272, 30), Validación: (2742, 30), Test: (8607, 30)\n",
      "Sujetos de prueba: [ 5 19 32 13 48 49]\n"
     ]
    }
   ],
   "source": [
    "subject_ids = df_final.get_column('subject_id').unique().to_numpy()\n",
    "train_subjects, temp_subjects = train_test_split(subject_ids, test_size=0.2, random_state=42)\n",
    "val_subjects, test_subjects = train_test_split(temp_subjects, test_size=0.5, random_state=42)\n",
    "\n",
    "train_mask = np.isin(df_final.get_column('subject_id').to_numpy(), train_subjects)\n",
    "val_mask = np.isin(df_final.get_column('subject_id').to_numpy(), val_subjects)\n",
    "test_mask = np.isin(df_final.get_column('subject_id').to_numpy(), test_subjects)\n",
    "\n",
    "X_train, y_train = X[train_mask], y[train_mask]\n",
    "X_val, y_val = X[val_mask], y[val_mask]\n",
    "X_test, y_test = X[test_mask], y[test_mask]\n",
    "subject_test = df_final.filter(pl.lit(test_mask)).get_column('subject_id').to_numpy()\n",
    "\n",
    "print(f\"Entrenamiento: {X_train.shape}, Validación: {X_val.shape}, Test: {X_test.shape}\")\n",
    "print(f\"Sujetos de prueba: {test_subjects}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 3: Establecimiento del ;odelo Base y Entrenamiento.\n",
    "\n",
    "Definición del modelo FNN (Feedforward Neural Network), ajustado para un conjunto más grande de datos.\n",
    "\n",
    "Entrenamiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,984</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m1,984\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,097</span> (16.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,097\u001b[0m (16.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,097</span> (16.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,097\u001b[0m (16.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (33272, 30) dtype: float32\n",
      "X_val shape: (2742, 30) dtype: float32\n",
      "y_train shape: (33272,) dtype: float32\n",
      "y_val shape: (2742,) dtype: float32\n",
      "\n",
      "Entrenando el modelo...\n",
      "Epoch 1/100\n",
      "\u001b[1m1040/1040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 18.5062 - val_loss: 2.3765\n",
      "Epoch 2/100\n",
      "\u001b[1m1040/1040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6.5213 - val_loss: 1.4072\n",
      "Epoch 3/100\n",
      "\u001b[1m1040/1040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5.7208 - val_loss: 1.4470\n",
      "Epoch 4/100\n",
      "\u001b[1m1040/1040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 5.3142 - val_loss: 1.2671\n",
      "Epoch 5/100\n",
      "\u001b[1m1040/1040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 5.3252 - val_loss: 1.0730\n",
      "Epoch 6/100\n",
      "\u001b[1m1040/1040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 4.6771 - val_loss: 1.1519\n",
      "Epoch 7/100\n",
      "\u001b[1m1040/1040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 4.4172 - val_loss: 1.0694\n",
      "Epoch 8/100\n",
      "\u001b[1m1040/1040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 4.3281 - val_loss: 1.1659\n",
      "Epoch 9/100\n",
      "\u001b[1m1040/1040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 4.1560 - val_loss: 1.1901\n",
      "Epoch 10/100\n",
      "\u001b[1m1040/1040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 4.3008 - val_loss: 1.3247\n",
      "Epoch 11/100\n",
      "\u001b[1m1040/1040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 3.8162 - val_loss: 1.3731\n",
      "Epoch 12/100\n",
      "\u001b[1m1040/1040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 3.8728 - val_loss: 1.2292\n",
      "Epoch 13/100\n",
      "\u001b[1m1040/1040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 3.7462 - val_loss: 1.6719\n",
      "Epoch 14/100\n",
      "\u001b[1m1040/1040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 3.5115 - val_loss: 1.2878\n",
      "Epoch 15/100\n",
      "\u001b[1m1040/1040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 3.9484 - val_loss: 1.2040\n",
      "Epoch 16/100\n",
      "\u001b[1m1040/1040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 3.5972 - val_loss: 1.3946\n",
      "Epoch 17/100\n",
      "\u001b[1m1040/1040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 3.4980 - val_loss: 1.2360\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mse')\n",
    "model.summary()\n",
    "\n",
    "# Convertir datos to float32\n",
    "X_train = np.array(X_train, dtype=np.float32)\n",
    "X_val = np.array(X_val, dtype=np.float32)\n",
    "y_train = np.array(y_train, dtype=np.float32)\n",
    "y_val = np.array(y_val, dtype=np.float32)\n",
    "\n",
    "# Verificar formas y tipos de datos.\n",
    "DTYPE_TEXT = \"dtype:\"\n",
    "print(\"X_train shape:\", X_train.shape, DTYPE_TEXT, X_train.dtype)\n",
    "print(\"X_val shape:\", X_val.shape, DTYPE_TEXT, X_val.dtype)\n",
    "print(\"y_train shape:\", y_train.shape, DTYPE_TEXT, y_train.dtype)\n",
    "print(\"y_val shape:\", y_val.shape, DTYPE_TEXT, y_val.dtype)\n",
    "\n",
    "# Entrenar el modelo.\n",
    "print(\"\\nEntrenando el modelo...\")\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 4: Graficación de los datos.\n",
    "\n",
    "Graficar el historial de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figura guardada en: /Users/tomas/Desktop/FIUBA/TPP/TPP_Deep_Learning_Models/figures/baseline/evolucion.png\n"
     ]
    }
   ],
   "source": [
    "figure_path = os.path.join(FIGURES_DIR, 'evolucion.png')\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['loss'], label='Pérdida del Entrenamiento')\n",
    "plt.plot(history.history['val_loss'], label='Pérdida de la Validación')\n",
    "plt.xlabel('Épocas/Epochs')\n",
    "plt.ylabel('Pérdida ECM/MSE Loss')\n",
    "plt.legend()\n",
    "plt.title('Historial de Entrenamiento (todos los sujetos)')\n",
    "plt.savefig(figure_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "print(f\"Figura guardada en: {figure_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 5: Evaluación del Modelo Base.\n",
    "\n",
    "Evaluar la performance del modelo según las métricas MAE, RMSE y R²."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m269/269\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "General MAE (Mean Absolute Error): 1.16 units\n",
      "General RMSE (Root Meean Squared Error): 1.62 units\n",
      "General R²: 0.54\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test).flatten()\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"General MAE (Mean Absolute Error): {mae:.2f} units\")\n",
    "print(f\"General RMSE (Root Meean Squared Error): {rmse:.2f} units\")\n",
    "print(f\"General R²: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza de X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen de valores eliminados:\n",
      "inf_values: 0\n",
      "too_large_values: 0\n",
      "nan_values: 0\n",
      "total_rows_removed: 0\n"
     ]
    }
   ],
   "source": [
    "def clean_array(arr: np.ndarray, return_counts: bool = False) -> tuple[np.ndarray, dict] | np.ndarray:\n",
    "    \"\"\"\n",
    "    Limpia un array numpy eliminando valores infinitos y demasiado grandes para float64.\n",
    "    \n",
    "    Parámeteros:\n",
    "    -----------\n",
    "    arr : np.ndarray\n",
    "        Array a limpiar\n",
    "    return_counts : bool, optional\n",
    "        Si es True, se devolverá un diccionario con los conteos de valores eliminados\n",
    "        \n",
    "    Retorna:\n",
    "    --------\n",
    "    np.ndarray o tuple[np.ndarray, dict]\n",
    "        Array limpio o tupla con array limpio y diccionario\n",
    "    \"\"\"\n",
    "    # Verificar dimensiones del array\n",
    "    if arr.ndim != 2:\n",
    "        raise ValueError(f\"El array debe ser 2D. Forma actual: {arr.shape}\")\n",
    "    \n",
    "    max_float = np.finfo(np.float64).max\n",
    "    min_float = np.finfo(np.float64).min\n",
    "    \n",
    "    # Crear máscaras para valores problemáticos\n",
    "    inf_mask = np.isinf(arr)\n",
    "    too_large_mask = (arr > max_float) | (arr < min_float)\n",
    "    nan_mask = np.isnan(arr)\n",
    "    \n",
    "    # Combinar máscaras\n",
    "    problem_mask = inf_mask | too_large_mask | nan_mask\n",
    "    # Convertir a máscara por filas\n",
    "    row_mask = ~np.any(problem_mask, axis=1)\n",
    "    \n",
    "    # Contar valores problemáticos\n",
    "    counts = {\n",
    "        'inf_values': np.sum(inf_mask),\n",
    "        'too_large_values': np.sum(too_large_mask & ~inf_mask),\n",
    "        'nan_values': np.sum(nan_mask),\n",
    "        'total_rows_removed': np.sum(~row_mask)\n",
    "    }\n",
    "    \n",
    "    # Limpiar array manteniendo la forma 2D\n",
    "    cleaned_arr = arr[row_mask]\n",
    "    \n",
    "    if return_counts:\n",
    "        return cleaned_arr, counts\n",
    "    return cleaned_arr\n",
    "\n",
    "X_test_cleaned, counts = clean_array(X_test, return_counts=True)\n",
    "print(f\"Resumen de valores eliminados:\")\n",
    "for k, v in counts.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Línea base basada en reglas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advertencia: 1165 predicciones no pudieron calcularse debido a ICR o ISF igual a cero\n",
      "Error en la predicción basada en reglas: Input contains NaN.\n",
      "\n",
      "Detalles de los datos:\n",
      "Shape de X_test: (8607, 30)\n",
      "NaN en X_test: 0\n",
      "NaN en y_test: 0\n"
     ]
    }
   ],
   "source": [
    "# Línea base basada en reglas.\n",
    "def rule_based_prediction(arr: np.ndarray, target_bg: float = 100.0) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Función para predecir la dosis de insulina basada en reglas.\n",
    "    \n",
    "    Parámetros:\n",
    "    -----------\n",
    "    arr : np.ndarray\n",
    "        Array 2D de entrada con features\n",
    "    target_bg : float\n",
    "        Valor objetivo de glucosa en sangre\n",
    "        \n",
    "    Retorna:\n",
    "    --------\n",
    "    np.ndarray\n",
    "        Predicciones de dosis de insulina\n",
    "    \"\"\"\n",
    "    # Verificar dimensiones\n",
    "    if arr.ndim != 2:\n",
    "        raise ValueError(f\"El array debe ser 2D. Forma actual: {arr.shape}\")\n",
    "    \n",
    "    if arr.shape[1] < 29:\n",
    "        raise ValueError(f\"El array debe tener al menos 29 columnas. Actuales: {arr.shape[1]}\")\n",
    "    \n",
    "    # Transformar datos una sola vez\n",
    "    transformed_data = scaler_other.inverse_transform(arr[:, 24:27])\n",
    "    \n",
    "    # Extraer features\n",
    "    carb_input = transformed_data[:, 0]\n",
    "    bg_input = transformed_data[:, 1]\n",
    "    icr = arr[:, 27]\n",
    "    isf = arr[:, 28]\n",
    "    \n",
    "    # Crear máscara para valores válidos\n",
    "    valid_mask = (icr != 0) & (isf != 0)\n",
    "    \n",
    "    # Inicializar array de predicciones con NaN\n",
    "    predictions = np.full(len(arr), np.nan)\n",
    "    \n",
    "    # Calcular predicciones solo donde ICR e ISF son válidos\n",
    "    predictions[valid_mask] = (\n",
    "        carb_input[valid_mask] / icr[valid_mask] + \n",
    "        (bg_input[valid_mask] - target_bg) / isf[valid_mask]\n",
    "    )\n",
    "    \n",
    "    # Casos inválidos:\n",
    "    if not np.all(valid_mask):\n",
    "        print(f\"Advertencia: {np.sum(~valid_mask)} predicciones no pudieron calcularse debido a ICR o ISF igual a cero\")\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "try:\n",
    "    y_rule = rule_based_prediction(X_test_cleaned)\n",
    "    mae_rule = mean_absolute_error(y_test, y_rule)\n",
    "    rmse_rule = np.sqrt(mean_squared_error(y_test, y_rule))\n",
    "    r2_rule = r2_score(y_test, y_rule)\n",
    "    print(f\"MAE basado en reglas: {mae_rule:.2f} u. de insulina.\")\n",
    "    print(f\"RMSE basado en reglas: {rmse_rule:.2f} u. de insulina.\")\n",
    "    print(f\"R² basado en reglas: {r2_rule:.2f}\")\n",
    "except ValueError as e:\n",
    "    print(f\"Error en la predicción basada en reglas: {str(e)}\")\n",
    "    print(\"\\nDetalles de los datos:\")\n",
    "    print(f\"Shape de X_test: {X_test.shape}\")\n",
    "    print(f\"NaN en X_test: {np.isnan(X_test).sum()}\")\n",
    "    print(f\"NaN en y_test: {np.isnan(y_test).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas por Sujeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rendimiento por sujeto:\n",
      "Sujeto 5: FNN MAE=1.24, RMSE=1.52, R²=-0.38, MAE basado en reglas=1.87\n",
      "Sujeto 19: FNN MAE=1.75, RMSE=2.07, R²=0.32, MAE basado en reglas=1.25\n",
      "Sujeto 32: FNN MAE=0.81, RMSE=1.18, R²=0.72, MAE basado en reglas=1.73\n",
      "Sujeto 13: FNN MAE=0.92, RMSE=1.05, R²=-0.52, MAE basado en reglas=1.17\n",
      "Sujeto 48: FNN MAE=1.06, RMSE=1.35, R²=0.12, MAE basado en reglas=N/A\n",
      "Sujeto 49: FNN MAE=2.38, RMSE=3.55, R²=0.37, MAE basado en reglas=2.14\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRendimiento por sujeto:\")\n",
    "for subject_id in test_subjects:\n",
    "    mask = subject_test == subject_id\n",
    "    y_test_sub = y_test[mask]\n",
    "    y_pred_sub = y_pred[mask]\n",
    "    \n",
    "    # Clean data for subject-wise metrics\n",
    "    sub_data = np.column_stack([y_test_sub, y_pred_sub])\n",
    "    is_finite = np.all(np.isfinite(sub_data), axis=1)\n",
    "    \n",
    "    if len(y_test_sub) > 0 and np.any(is_finite):\n",
    "        # Use only finite values for metrics\n",
    "        y_test_clean = y_test_sub[is_finite]\n",
    "        y_pred_clean = y_pred_sub[is_finite]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mae_sub = mean_absolute_error(y_test_clean, y_pred_clean)\n",
    "        rmse_sub = np.sqrt(mean_squared_error(y_test_clean, y_pred_clean))\n",
    "        r2_sub = r2_score(y_test_clean, y_pred_clean)\n",
    "        \n",
    "        # Rule-based metrics if available\n",
    "        try:\n",
    "            y_rule_sub = y_rule[mask][is_finite]\n",
    "            mae_rule_sub = mean_absolute_error(y_test_clean, y_rule_sub)\n",
    "            print(\n",
    "                f\"Sujeto {subject_id}: \"\n",
    "                f\"FNN MAE={mae_sub:.2f}, \"\n",
    "                f\"RMSE={rmse_sub:.2f}, \"\n",
    "                f\"R²={r2_sub:.2f}, \"\n",
    "                f\"MAE basado en reglas={mae_rule_sub:.2f}\"\n",
    "            )\n",
    "        except (IndexError, ValueError):\n",
    "            print(\n",
    "                f\"Sujeto {subject_id}: \"\n",
    "                f\"FNN MAE={mae_sub:.2f}, \"\n",
    "                f\"RMSE={rmse_sub:.2f}, \"\n",
    "                f\"R²={r2_sub:.2f}, \"\n",
    "                f\"MAE basado en reglas=N/A\"\n",
    "            )\n",
    "    else:\n",
    "        print(f\"Sujeto {subject_id}: No hay suficientes datos válidos para calcular métricas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separación de Datos\n",
    "\n",
    "Separación entre datos limpios y residuales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores infinitos removidos:\n",
      "FNN: 0 valores\n",
      "Basado en reglas: 1165 valores\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x500 with 0 Axes>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_residuals(actual, predicted):\n",
    "    \"\"\"\n",
    "    Limpia los residuos eliminando valores infinitos.\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    - np.ndarray\n",
    "        Residuos limpios\n",
    "    - int\n",
    "        Número de valores eliminados\n",
    "    \"\"\"\n",
    "    residuals = actual - predicted\n",
    "    mask = np.isfinite(residuals)\n",
    "    n_dropped = np.sum(~mask)\n",
    "    return residuals[mask], n_dropped\n",
    "\n",
    "fnn_residuals, fnn_dropped = clean_residuals(y_test, y_pred)\n",
    "rule_residuals, rule_dropped = clean_residuals(y_test, y_rule)\n",
    "\n",
    "print(f\"\\nValores infinitos removidos:\")\n",
    "print(f\"FNN: {fnn_dropped} valores\")\n",
    "print(f\"Basado en reglas: {rule_dropped} valores\")\n",
    "\n",
    "plt.figure(figsize=(12, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicción vs Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Predicción vs. Real (Todos los Sujetos)')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "mask_pred = np.isfinite(y_pred)\n",
    "mask_rule = np.isfinite(y_rule)\n",
    "\n",
    "plt.scatter(y_test[mask_pred], y_pred[mask_pred], label='Predicción FNN', alpha=0.5)\n",
    "plt.scatter(y_test[mask_rule], y_rule[mask_rule], label='Basado en Reglas', alpha=0.5)\n",
    "plt.plot([0, 15], [0, 15], 'r--')\n",
    "plt.xlabel('Dosis Real (u. de insulina)')\n",
    "plt.ylabel('Dosis Predicha (u. de insulina)')\n",
    "plt.legend()\n",
    "plt.title('Predicción vs. Real (Todos los Sujetos)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Residuales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Distribución de Residuos (Todos los Sujetos)')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(fnn_residuals, bins=20, label='Residuales FNN', alpha=0.5)\n",
    "plt.hist(rule_residuals, bins=20, label='Residuos Basados en Reglas', alpha=0.5)\n",
    "plt.xlabel('Residuo (u. de insulina)')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.legend()\n",
    "plt.title('Distribución de Residuos (Todos los Sujetos)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIGURES_DIR, 'pred_vs_real.png'), dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
